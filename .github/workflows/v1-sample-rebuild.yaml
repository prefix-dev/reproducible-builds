name: V1 Recipe Sampling

on:
  workflow_dispatch:
    inputs:
      sample_size:
        description: "Number of V1 packages to sample"
        required: true
        default: "20"
      seed:
        description: "Random seed for reproducible sampling (optional)"
        required: false
      max_age_days:
        description: "Maximum age of packages in days"
        required: false
        default: "10"

  schedule:
    # Run daily at 3 AM UTC
    - cron: '0 3 * * *'

env:
  RATTLER_BUILD_ENABLE_GITHUB_INTEGRATION: true
  REPRO_DB_NAME: repro.db
  REPRO_DOCS_DIR: docs
  PYTHONUTF8: 1

jobs:
  generate-v1-packages:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.generate-matrix.outputs.matrix }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - uses: prefix-dev/setup-pixi@v0.8.1
        with:
          pixi-version: "latest"
          cache: true

      - name: Generate V1 package matrix
        id: generate-matrix
        run: |
          SAMPLE_SIZE="${{ github.event.inputs.sample_size || '20' }}"
          SEED="${{ github.event.inputs.seed }}"
          MAX_AGE="${{ github.event.inputs.max_age_days || '10' }}"

          SEED_ARG=""
          if [ -n "$SEED" ]; then
            SEED_ARG="--seed $SEED"
          fi

          # Generate matrix with full package info for noarch (faster rebuilds)
          # The generate-matrix command outputs JSON to stdout, status to stderr
          MATRIX_JSON=$(pixi run repror v1 generate-matrix \
            --size "$SAMPLE_SIZE" \
            --subdir noarch \
            --max-age-days "$MAX_AGE" \
            $SEED_ARG)

          echo "matrix=$MATRIX_JSON" >> "$GITHUB_OUTPUT"
          echo "Generated matrix with $(echo "$MATRIX_JSON" | jq length) packages"
        env:
          LOG_LEVEL: WARNING

  rebuild-v1-packages:
    needs: generate-v1-packages
    if: ${{ needs.generate-v1-packages.outputs.matrix != '[]' }}
    name: v1-${{ matrix.package.name }}-${{ matrix.package.version }}-${{ matrix.os }}
    continue-on-error: true
    strategy:
      fail-fast: false
      matrix:
        package: ${{ fromJson(needs.generate-v1-packages.outputs.matrix) }}
        os: [ubuntu-latest]
        # Note: macOS packages have different subdirs, would need separate matrix generation

    runs-on: ${{ matrix.os }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - uses: prefix-dev/setup-pixi@v0.8.1
        with:
          pixi-version: "latest"
          cache: true

      - name: Create conda-forge build directory structure
        run: |
          # rattler-build rebuild tries to use the original build paths from conda-forge
          # We need to create these directories with write permissions
          sudo mkdir -p /home/conda/feedstock_root/build_artifacts
          sudo chown -R $USER:$USER /home/conda
        if: runner.os == 'Linux'

      - name: Rebuild V1 package
        run: |
          # Pass package info as JSON directly - no need to re-fetch repodata
          PACKAGE_INFO='${{ toJson(matrix.package) }}'
          pixi run repror v1 rebuild-one \
            --package-info "$PACKAGE_INFO" \
            --actions-url "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}" \
            --patch
        env:
          LOG_LEVEL: WARNING

      - name: Upload patch artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: v1-patch-${{ matrix.package.name }}-${{ matrix.package.version }}-${{ matrix.os }}
          path: build_info/v1/
          if-no-files-found: ignore

      - name: Upload diff artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: v1-diff-${{ matrix.package.name }}-${{ matrix.package.version }}-${{ matrix.os }}
          path: build_info/v1/diffs/
          if-no-files-found: ignore

  patch-v1-db:
    runs-on: ubuntu-latest
    needs: rebuild-v1-packages
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - uses: prefix-dev/setup-pixi@v0.8.1
        with:
          pixi-version: "latest"
          cache: true

      - name: Download all patch artifacts
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: v1-patch-*
          path: build_info/v1/
          merge-multiple: true

      - name: List patches
        continue-on-error: true
        run: |
          echo "=== V1 Patches ==="
          find build_info/v1 -name "*.json" 2>/dev/null || echo "No patches found"

      - name: Download existing database from release
        continue-on-error: true
        run: |
          gh release download database --pattern 'repro.db' --clobber || echo "No existing database release found"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Merge V1 patches to database
        run: |
          pixi run python << 'EOF'
          import sys
          sys.path.insert(0, 'src')

          from repror.internals.db import setup_engine
          from repror.internals.patch_database import patch_v1_rebuilds_to_db

          setup_engine()
          count = patch_v1_rebuilds_to_db("build_info/v1")
          print(f"Merged {count} V1 rebuild patches")
          EOF

      - name: Upload database to release
        if: github.ref == 'refs/heads/main'
        run: |
          # Create release if it doesn't exist
          gh release view database || gh release create database --title "Database" --notes "Auto-updated reproducibility database"
          # Upload/update the database file
          gh release upload database repro.db --clobber
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  generate-html:
    runs-on: ubuntu-latest
    needs: patch-v1-db
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - uses: prefix-dev/setup-pixi@v0.8.1
        with:
          pixi-version: "latest"
          cache: true

      - name: Download database from release
        continue-on-error: true
        run: |
          gh release download database --pattern 'repro.db' --clobber || echo "No database release found"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Download all diff artifacts
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          pattern: v1-diff-*
          path: diffs_staging/
          merge-multiple: true

      - name: Upload diffs to release
        if: github.ref == 'refs/heads/main'
        run: |
          # Create diffs release if it doesn't exist
          gh release view diffs || gh release create diffs --title "Diffoscope Reports" --notes "Auto-updated diffoscope HTML reports for non-reproducible packages"

          # Find and upload all diff HTML files
          if [ -d "diffs_staging" ]; then
            echo "=== Uploading diffs to release ==="
            find diffs_staging -type f -name "*.html" | while read -r file; do
              # Get just the filename for the asset name
              basename=$(basename "$file")
              echo "Uploading: $basename"
              gh release upload diffs "$file" --clobber || echo "Failed to upload $file"
            done
            echo "Done uploading diffs"
          else
            echo "No diffs to upload"
          fi
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: List uploaded diffs
        continue-on-error: true
        run: |
          echo "=== Diffs in release ==="
          gh release view diffs --json assets -q '.assets[].name' | head -30 || echo "No diffs release"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Generate HTML pages
        run: |
          pixi run repror generate-html

      - name: Update remote docs via API
        if: github.ref == 'refs/heads/main'
        run: |
          REPROR_UPDATE_TOKEN=${{ secrets.GITHUB_TOKEN }} pixi run repror generate-html --update-remote

  summarize-results:
    runs-on: ubuntu-latest
    needs: generate-html
    if: always()
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - uses: prefix-dev/setup-pixi@v0.8.1
        with:
          pixi-version: "latest"
          cache: true

      - name: Download database from release
        continue-on-error: true
        run: |
          gh release download database --pattern 'repro.db' --clobber || echo "No database release found"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Generate summary
        run: |
          pixi run python << 'EOF' >> $GITHUB_STEP_SUMMARY
          import sys
          sys.path.insert(0, 'src')

          from repror.internals.db import setup_engine, get_session, V1Rebuild, BuildState
          from sqlmodel import select, func

          setup_engine()

          print("## V1 Recipe Rebuild Results\n")

          with get_session() as session:
              total = session.exec(select(func.count(V1Rebuild.id))).one()
              successful = session.exec(
                  select(func.count(V1Rebuild.id)).where(V1Rebuild.state == BuildState.SUCCESS)
              ).one()
              reproducible = session.exec(
                  select(func.count(V1Rebuild.id)).where(
                      V1Rebuild.state == BuildState.SUCCESS,
                      V1Rebuild.original_hash == V1Rebuild.rebuild_hash
                  )
              ).one()

              print(f"| Metric | Count |")
              print(f"|--------|-------|")
              print(f"| Total V1 rebuilds | {total} |")
              print(f"| Successful rebuilds | {successful} |")
              print(f"| Reproducible | {reproducible} |")

              if successful > 0:
                  rate = 100 * reproducible / successful
                  print(f"| Reproducibility rate | {rate:.1f}% |")

              print("\n### View Results")
              print("- [Recipe Builds Dashboard](https://prefix-dev.github.io/reproducible-builds/)")
              print("- [Conda-Forge Rebuilds](https://prefix-dev.github.io/reproducible-builds/v1.html)")
          EOF
